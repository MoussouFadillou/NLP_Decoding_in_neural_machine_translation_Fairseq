{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Moussou_Fairseq_generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbNPO5Toi8rC"
      },
      "source": [
        "# FAIRSEQ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9zKnOrgi8rI"
      },
      "source": [
        "from https://fairseq.readthedocs.io/en/latest/getting_started.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM6XXIRgi8rJ"
      },
      "source": [
        "\"Fairseq(-py) is a sequence modeling toolkit that allows researchers and developers to train custom models for translation, summarization, language modeling and other text generation tasks.\" It provides reference implementations of various sequence-to-sequence models making our life much more easier!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM11T-d7i8rJ"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBC0Fkjni8rK"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSD2XoxFi8rK"
      },
      "source": [
        "!pip install --upgrade fairseq\n",
        "!pip install sacremoses subword_nmt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3gTFLU8i8rK"
      },
      "source": [
        "## Generation using pre-trained MT model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUbTNqX3i8rL",
        "outputId": "84764e18-d20b-4d57-b11d-d3ed7b70771b"
      },
      "source": [
        "! curl https://dl.fbaipublicfiles.com/fairseq/models/wmt14.v2.en-fr.fconv-py.tar.bz2 | tar xvjf -"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0 1909M    0  7727    0     0  11296      0 49:14:15 --:--:-- 49:14:15 11280wmt14.en-fr.fconv-py/\n",
            "wmt14.en-fr.fconv-py/model.pt\n",
            " 99 1909M   99 1906M    0     0  5833k      0  0:05:35  0:05:34  0:00:01 5972kwmt14.en-fr.fconv-py/dict.en.txt\n",
            "wmt14.en-fr.fconv-py/dict.fr.txt\n",
            "100 1909M  100 1909M    0     0  5832k      0  0:05:35  0:05:35 --:--:-- 5933k\n",
            "wmt14.en-fr.fconv-py/bpecodes\n",
            "wmt14.en-fr.fconv-py/README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhOle-js7dui"
      },
      "source": [
        "We're going to use this downloaded model in an interactive setting and try out all the decoding algorithms we learnt about! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-xWsnQvDz1t"
      },
      "source": [
        "##### First lets try out standard beam search - "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6Lqv_NHFopk",
        "outputId": "fdfda3da-ab3f-4548-e4c0-4e6c9489127e"
      },
      "source": [
        "%%bash\n",
        "MODEL_DIR=wmt14.en-fr.fconv-py\n",
        "echo \"Please tell me your name and a little about yourself .\" | fairseq-interactive \\\n",
        "    --path $MODEL_DIR/model.pt $MODEL_DIR \\\n",
        "    --tokenizer moses --bpe subword_nmt --bpe-codes $MODEL_DIR/bpecodes  \\\n",
        "    --beam 5 --nbest 5 --source-lang en --target-lang fr --remove-bpe "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-08 16:44:25 | INFO | fairseq_cli.interactive | Namespace(all_gather_list_size=16384, batch_size=1, batch_size_valid=None, beam=5, bf16=False, bpe='subword_nmt', bpe_codes='wmt14.en-fr.fconv-py/bpecodes', bpe_separator='@@', broadcast_buffers=False, bucket_cap_mb=25, buffer_size=1, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='wmt14.en-fr.fconv-py', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=0, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', input='-', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, moses_no_dash_splits=False, moses_no_escape=False, moses_source_lang=None, moses_target_lang=None, nbest=5, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='wmt14.en-fr.fconv-py/model.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe='@@ ', replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', target_lang='fr', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer='moses', tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2021-04-08 16:44:25 | INFO | fairseq.tasks.translation | [en] dictionary: 43771 types\n",
            "2021-04-08 16:44:25 | INFO | fairseq.tasks.translation | [fr] dictionary: 43807 types\n",
            "2021-04-08 16:44:25 | INFO | fairseq_cli.interactive | loading model(s) from wmt14.en-fr.fconv-py/model.pt\n",
            "2021-04-08 16:44:37 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n",
            "2021-04-08 16:44:37 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n",
            "S-0\tPlease tell me your name and a little about yourself .\n",
            "W-0\t2.392\tseconds\n",
            "H-0\t-0.5719991326332092\tDites @-@ moi votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.5719991326332092\tDites-moi votre nom et un peu de vous-même.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -1.5301 -0.6950 -0.3036 -0.1695 -0.1824\n",
            "H-0\t-0.6281494498252869\tVeuillez me dire votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.6281494498252869\tVeuillez me dire votre nom et un peu de vous-même.\n",
            "P-0\t-2.7564 -0.3864 -0.8797 -0.4312 -0.1721 -0.3034 -0.6297 -0.1994 -0.7686 -0.9387 -0.7073 -0.2819 -0.1579 -0.1815\n",
            "H-0\t-0.7276960611343384\tDites @-@ moi votre nom et un peu de vous .\n",
            "D-0\t-0.7276960611343384\tDites-moi votre nom et un peu de vous.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -1.5301 -2.0434 -0.1872\n",
            "H-0\t-0.793375551700592\tDites @-@ moi votre nom et un peu sur vous .\n",
            "D-0\t-0.793375551700592\tDites-moi votre nom et un peu sur vous.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -3.4049 -0.3754 -1.1687 -0.1849\n",
            "H-0\t-0.8001118898391724\tVeuillez me dire votre nom et un peu sur vous .\n",
            "D-0\t-0.8001118898391724\tVeuillez me dire votre nom et un peu sur vous.\n",
            "P-0\t-2.7564 -0.3864 -0.8797 -0.4312 -0.1721 -0.3034 -0.6297 -0.1994 -2.3226 -0.2832 -1.0518 -0.1854\n",
            "2021-04-08 16:44:39 | INFO | fairseq_cli.interactive | Total time: 14.225 seconds; translation time: 2.392\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHbfXbxgL2xc"
      },
      "source": [
        "This generation script produces three types of outputs: a line prefixed with O is a copy of the original source sentence; H is the hypothesis along with an average log-likelihood; and P is the positional score per token position, including the end-of-sentence marker which is omitted from the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhX7jS6sGG9G",
        "outputId": "cdeacd38-7109-4a9b-b709-96758ecd2288"
      },
      "source": [
        "%%bash\n",
        "MODEL_DIR=wmt14.en-fr.fconv-py\n",
        "echo \"Please tell me your name and a little about yourself .\" | fairseq-interactive \\\n",
        "    --path $MODEL_DIR/model.pt $MODEL_DIR \\\n",
        "    --tokenizer moses --bpe subword_nmt --bpe-codes $MODEL_DIR/bpecodes  \\\n",
        "    --beam 100 --nbest 5 --source-lang en --target-lang fr --remove-bpe "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-08 16:45:09 | INFO | fairseq_cli.interactive | Namespace(all_gather_list_size=16384, batch_size=1, batch_size_valid=None, beam=100, bf16=False, bpe='subword_nmt', bpe_codes='wmt14.en-fr.fconv-py/bpecodes', bpe_separator='@@', broadcast_buffers=False, bucket_cap_mb=25, buffer_size=1, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='wmt14.en-fr.fconv-py', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=0, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', input='-', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, moses_no_dash_splits=False, moses_no_escape=False, moses_source_lang=None, moses_target_lang=None, nbest=5, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='wmt14.en-fr.fconv-py/model.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe='@@ ', replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', target_lang='fr', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer='moses', tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2021-04-08 16:45:09 | INFO | fairseq.tasks.translation | [en] dictionary: 43771 types\n",
            "2021-04-08 16:45:09 | INFO | fairseq.tasks.translation | [fr] dictionary: 43807 types\n",
            "2021-04-08 16:45:09 | INFO | fairseq_cli.interactive | loading model(s) from wmt14.en-fr.fconv-py/model.pt\n",
            "2021-04-08 16:45:20 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n",
            "2021-04-08 16:45:20 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n",
            "S-0\tPlease tell me your name and a little about yourself .\n",
            "W-0\t10.118\tseconds\n",
            "H-0\t-0.5719991326332092\tDites @-@ moi votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.5719991326332092\tDites-moi votre nom et un peu de vous-même.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -1.5301 -0.6950 -0.3036 -0.1695 -0.1824\n",
            "H-0\t-0.6281494498252869\tVeuillez me dire votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.6281494498252869\tVeuillez me dire votre nom et un peu de vous-même.\n",
            "P-0\t-2.7564 -0.3864 -0.8797 -0.4312 -0.1721 -0.3034 -0.6297 -0.1994 -0.7686 -0.9387 -0.7073 -0.2819 -0.1579 -0.1815\n",
            "H-0\t-0.7244848012924194\tDites @-@ moi votre nom et un peu sur vous @-@ même .\n",
            "D-0\t-0.7244848012924194\tDites-moi votre nom et un peu sur vous-même.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -3.4049 -0.3754 -1.2054 -0.3654 -0.1554 -0.1808\n",
            "H-0\t-0.7276952862739563\tDites @-@ moi votre nom et un peu de vous .\n",
            "D-0\t-0.7276952862739563\tDites-moi votre nom et un peu de vous.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -1.5301 -2.0433 -0.1872\n",
            "H-0\t-0.7343103885650635\tDites @-@ moi votre nom et quelques mots sur vous @-@ même .\n",
            "D-0\t-0.7343103885650635\tDites-moi votre nom et quelques mots sur vous-même.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -2.1724 -2.0234 -0.7167 -0.4778 -0.8385 -0.4498 -0.1630 -0.1802\n",
            "2021-04-08 16:45:31 | INFO | fairseq_cli.interactive | Total time: 21.697 seconds; translation time: 10.118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeoSHSx8Y7ki"
      },
      "source": [
        "Diverse beam search produces much more varied generation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKRgFTN8QtV9",
        "outputId": "6c74135c-8c40-47fd-e6c6-7291fc53f505"
      },
      "source": [
        "%%bash\n",
        "MODEL_DIR=wmt14.en-fr.fconv-py\n",
        "echo \"Please tell me your name and a little about yourself .\" | fairseq-interactive \\\n",
        "    --path $MODEL_DIR/model.pt $MODEL_DIR \\\n",
        "    --tokenizer moses --bpe subword_nmt --bpe-codes $MODEL_DIR/bpecodes  \\\n",
        "    --beam 5 --nbest 5 --source-lang en --target-lang fr --remove-bpe --diverse-beam-groups 5 --diverse-beam-strength 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-08 16:45:52 | INFO | fairseq_cli.interactive | Namespace(all_gather_list_size=16384, batch_size=1, batch_size_valid=None, beam=5, bf16=False, bpe='subword_nmt', bpe_codes='wmt14.en-fr.fconv-py/bpecodes', bpe_separator='@@', broadcast_buffers=False, bucket_cap_mb=25, buffer_size=1, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='wmt14.en-fr.fconv-py', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=0, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=5, diverse_beam_strength=10.0, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', input='-', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, moses_no_dash_splits=False, moses_no_escape=False, moses_source_lang=None, moses_target_lang=None, nbest=5, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='wmt14.en-fr.fconv-py/model.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe='@@ ', replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', target_lang='fr', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer='moses', tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2021-04-08 16:45:52 | INFO | fairseq.tasks.translation | [en] dictionary: 43771 types\n",
            "2021-04-08 16:45:52 | INFO | fairseq.tasks.translation | [fr] dictionary: 43807 types\n",
            "2021-04-08 16:45:52 | INFO | fairseq_cli.interactive | loading model(s) from wmt14.en-fr.fconv-py/model.pt\n",
            "2021-04-08 16:46:03 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n",
            "2021-04-08 16:46:03 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n",
            "S-0\tPlease tell me your name and a little about yourself .\n",
            "W-0\t2.369\tseconds\n",
            "H-0\t-0.5719991326332092\tDites @-@ moi votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.5719991326332092\tDites-moi votre nom et un peu de vous-même.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -1.5301 -0.6950 -0.3036 -0.1695 -0.1824\n",
            "H-0\t-1.8039686679840088\tMerci de me dire ton prénom et un peu de toi .\n",
            "D-0\t-1.8039686679840088\tMerci de me dire ton prénom et un peu de toi.\n",
            "P-0\t-4.9458 -0.2245 -0.3576 -1.1888 -4.5186 -9.0919 -0.0152 -0.3292 -1.2532 -0.2600 -0.4751 -1.0977 -1.3169 -0.1812\n",
            "H-0\t-1.932053804397583\tParlez de votre nom et de vos commentaires .\n",
            "D-0\t-1.932053804397583\tParlez de votre nom et de vos commentaires.\n",
            "P-0\t-4.4182 -0.1850 -6.1575 -1.2460 -0.3455 -0.2942 -1.2999 -1.9015 -4.5389 -0.6827 -0.1833\n",
            "H-0\t-2.4697072505950928\tDites @-@ moi votre nom et un peu de votre personne ! ... ?\n",
            "D-0\t-2.4697072505950928\tDites-moi votre nom et un peu de votre personne !... ?\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -3.2302 -2.5714 -6.6439 -12.8658 -8.1906 -0.3139\n",
            "H-0\t-2.8107852935791016\tFaites @-@ nous part de votre identité .\n",
            "D-0\t-2.8107852935791016\tFaites-nous part de votre identité.\n",
            "P-0\t-6.3486 -0.2764 -6.6879 -0.5047 -0.1712 -0.5412 -6.4277 -4.0507 -0.2888\n",
            "2021-04-08 16:46:06 | INFO | fairseq_cli.interactive | Total time: 13.937 seconds; translation time: 2.369\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2KKChN1i8rO"
      },
      "source": [
        "Let's try using different decoding methods for generation and see what results we get!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVB2NqLTxRdz",
        "outputId": "ace63f2b-6307-4bb9-f9a0-926f2057cc02"
      },
      "source": [
        "%%bash\n",
        "MODEL_DIR=wmt14.en-fr.fconv-py\n",
        "echo \"Please tell me your name and a little about yourself .\" | fairseq-interactive \\\n",
        "    --path $MODEL_DIR/model.pt $MODEL_DIR \\\n",
        "    --tokenizer moses --bpe subword_nmt --bpe-codes $MODEL_DIR/bpecodes  \\\n",
        "    --sampling --sampling-topk 10 --nbest 5 --source-lang en --target-lang fr --remove-bpe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-08 16:46:24 | INFO | fairseq_cli.interactive | Namespace(all_gather_list_size=16384, batch_size=1, batch_size_valid=None, beam=5, bf16=False, bpe='subword_nmt', bpe_codes='wmt14.en-fr.fconv-py/bpecodes', bpe_separator='@@', broadcast_buffers=False, bucket_cap_mb=25, buffer_size=1, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='wmt14.en-fr.fconv-py', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=0, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', input='-', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, moses_no_dash_splits=False, moses_no_escape=False, moses_source_lang=None, moses_target_lang=None, nbest=5, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='wmt14.en-fr.fconv-py/model.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe='@@ ', replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=True, sampling_topk=10, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', target_lang='fr', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer='moses', tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2021-04-08 16:46:24 | INFO | fairseq.tasks.translation | [en] dictionary: 43771 types\n",
            "2021-04-08 16:46:24 | INFO | fairseq.tasks.translation | [fr] dictionary: 43807 types\n",
            "2021-04-08 16:46:24 | INFO | fairseq_cli.interactive | loading model(s) from wmt14.en-fr.fconv-py/model.pt\n",
            "2021-04-08 16:46:38 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n",
            "2021-04-08 16:46:38 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n",
            "S-0\tPlease tell me your name and a little about yourself .\n",
            "W-0\t2.452\tseconds\n",
            "H-0\t-1.0527796745300293\tParlez @-@ moi de votre nom et de votre personne .\n",
            "D-0\t-1.0527796745300293\tParlez-moi de votre nom et de votre personne.\n",
            "P-0\t-4.4182 -0.1850 -0.1128 -0.1384 -0.5004 -0.4837 -0.2584 -0.2395 -1.2135 -2.0609 -3.5716 -0.3204 -0.1834\n",
            "H-0\t-1.287907600402832\tVeuillez me donner vos nom et un peu de vous @-@ même .\n",
            "D-0\t-1.287907600402832\tVeuillez me donner vos nom et un peu de vous-même.\n",
            "P-0\t-2.7564 -0.3864 -2.8707 -4.1290 -2.0628 -0.2221 -1.8097 -0.3798 -0.6341 -1.4104 -0.7302 -0.2889 -0.1687 -0.1817\n",
            "H-0\t-1.373555064201355\tVeuillez me dire votre nom et un peu de vos propres yeux .\n",
            "D-0\t-1.373555064201355\tVeuillez me dire votre nom et un peu de vos propres yeux.\n",
            "P-0\t-2.7564 -0.3864 -0.8797 -0.4312 -0.1721 -0.3034 -0.6297 -0.1994 -0.7686 -5.1806 -3.5444 -3.6307 -0.1654 -0.1817\n",
            "H-0\t-1.6016371250152588\tVeuillez me dire votre nom en plus de vous parler .\n",
            "D-0\t-1.6016371250152588\tVeuillez me dire votre nom en plus de vous parler.\n",
            "P-0\t-2.7564 -0.3864 -0.8797 -0.4312 -0.1721 -9.0059 -1.0946 -0.6445 -1.0034 -0.8197 -1.8424 -0.1834\n",
            "H-0\t-1.813172459602356\tFaites @-@ moi part de votre adresse , de votre nom et de votre personnalité .\n",
            "D-0\t-1.813172459602356\tFaites-moi part de votre adresse, de votre nom et de votre personnalité.\n",
            "P-0\t-6.3486 -0.2764 -0.1921 -0.8476 -0.1666 -0.4705 -8.7628 -4.8857 -2.3746 -0.6913 -0.9729 -0.4558 -0.2187 -0.9814 -2.7996 -0.2010 -0.1784\n",
            "2021-04-08 16:46:41 | INFO | fairseq_cli.interactive | Total time: 17.391 seconds; translation time: 2.452\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXWhc_LA36ph",
        "outputId": "da95dea3-baeb-4d14-ca62-586a3e043a85"
      },
      "source": [
        "%%bash\n",
        "MODEL_DIR=wmt14.en-fr.fconv-py\n",
        "echo \"Please tell me your name and a little about yourself .\" | fairseq-interactive \\\n",
        "    --path $MODEL_DIR/model.pt $MODEL_DIR \\\n",
        "    --tokenizer moses --bpe subword_nmt --bpe-codes $MODEL_DIR/bpecodes  \\\n",
        "    --sampling --sampling-topp 0.1 --nbest 5 --source-lang en --target-lang fr --remove-bpe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-08 16:50:19 | INFO | fairseq_cli.interactive | Namespace(all_gather_list_size=16384, batch_size=1, batch_size_valid=None, beam=5, bf16=False, bpe='subword_nmt', bpe_codes='wmt14.en-fr.fconv-py/bpecodes', bpe_separator='@@', broadcast_buffers=False, bucket_cap_mb=25, buffer_size=1, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='wmt14.en-fr.fconv-py', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=0, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', input='-', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, moses_no_dash_splits=False, moses_no_escape=False, moses_source_lang=None, moses_target_lang=None, nbest=5, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='wmt14.en-fr.fconv-py/model.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe='@@ ', replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=True, sampling_topk=-1, sampling_topp=0.1, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', target_lang='fr', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer='moses', tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2021-04-08 16:50:19 | INFO | fairseq.tasks.translation | [en] dictionary: 43771 types\n",
            "2021-04-08 16:50:19 | INFO | fairseq.tasks.translation | [fr] dictionary: 43807 types\n",
            "2021-04-08 16:50:19 | INFO | fairseq_cli.interactive | loading model(s) from wmt14.en-fr.fconv-py/model.pt\n",
            "2021-04-08 16:50:30 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n",
            "2021-04-08 16:50:30 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n",
            "S-0\tPlease tell me your name and a little about yourself .\n",
            "W-0\t2.591\tseconds\n",
            "H-0\t-0.5719991326332092\tDites @-@ moi votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.5719991326332092\tDites-moi votre nom et un peu de vous-même.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -1.5301 -0.6950 -0.3036 -0.1695 -0.1824\n",
            "H-0\t-0.5719991326332092\tDites @-@ moi votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.5719991326332092\tDites-moi votre nom et un peu de vous-même.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -1.5301 -0.6950 -0.3036 -0.1695 -0.1824\n",
            "H-0\t-0.5719991326332092\tDites @-@ moi votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.5719991326332092\tDites-moi votre nom et un peu de vous-même.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -1.5301 -0.6950 -0.3036 -0.1695 -0.1824\n",
            "H-0\t-0.5719991326332092\tDites @-@ moi votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.5719991326332092\tDites-moi votre nom et un peu de vous-même.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -1.5301 -0.6950 -0.3036 -0.1695 -0.1824\n",
            "H-0\t-0.5719991326332092\tDites @-@ moi votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.5719991326332092\tDites-moi votre nom et un peu de vous-même.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -1.5301 -0.6950 -0.3036 -0.1695 -0.1824\n",
            "2021-04-08 16:50:33 | INFO | fairseq_cli.interactive | Total time: 14.384 seconds; translation time: 2.591\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5exFgO8N3-Wt",
        "outputId": "2d07540f-3173-48cc-afc0-367c85268dda"
      },
      "source": [
        "%%bash\n",
        "MODEL_DIR=wmt14.en-fr.fconv-py\n",
        "echo \"Please tell me your name and a little about yourself .\" | fairseq-interactive \\\n",
        "    --path $MODEL_DIR/model.pt $MODEL_DIR \\\n",
        "    --tokenizer moses --bpe subword_nmt --bpe-codes $MODEL_DIR/bpecodes  \\\n",
        "    --sampling --sampling-topp 0.5 --nbest 5 --source-lang en --target-lang fr --remove-bpe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-08 16:50:36 | INFO | fairseq_cli.interactive | Namespace(all_gather_list_size=16384, batch_size=1, batch_size_valid=None, beam=5, bf16=False, bpe='subword_nmt', bpe_codes='wmt14.en-fr.fconv-py/bpecodes', bpe_separator='@@', broadcast_buffers=False, bucket_cap_mb=25, buffer_size=1, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='wmt14.en-fr.fconv-py', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=0, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', input='-', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, moses_no_dash_splits=False, moses_no_escape=False, moses_source_lang=None, moses_target_lang=None, nbest=5, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='wmt14.en-fr.fconv-py/model.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe='@@ ', replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=True, sampling_topk=-1, sampling_topp=0.5, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', target_lang='fr', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer='moses', tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2021-04-08 16:50:36 | INFO | fairseq.tasks.translation | [en] dictionary: 43771 types\n",
            "2021-04-08 16:50:36 | INFO | fairseq.tasks.translation | [fr] dictionary: 43807 types\n",
            "2021-04-08 16:50:36 | INFO | fairseq_cli.interactive | loading model(s) from wmt14.en-fr.fconv-py/model.pt\n",
            "2021-04-08 16:50:47 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n",
            "2021-04-08 16:50:47 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n",
            "S-0\tPlease tell me your name and a little about yourself .\n",
            "W-0\t2.548\tseconds\n",
            "H-0\t-0.5719991326332092\tDites @-@ moi votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.5719991326332092\tDites-moi votre nom et un peu de vous-même.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -1.5301 -0.6950 -0.3036 -0.1695 -0.1824\n",
            "H-0\t-0.6281494498252869\tVeuillez me dire votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.6281494498252869\tVeuillez me dire votre nom et un peu de vous-même.\n",
            "P-0\t-2.7564 -0.3864 -0.8797 -0.4312 -0.1721 -0.3034 -0.6297 -0.1994 -0.7686 -0.9387 -0.7073 -0.2819 -0.1579 -0.1815\n",
            "H-0\t-0.6281494498252869\tVeuillez me dire votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.6281494498252869\tVeuillez me dire votre nom et un peu de vous-même.\n",
            "P-0\t-2.7564 -0.3864 -0.8797 -0.4312 -0.1721 -0.3034 -0.6297 -0.1994 -0.7686 -0.9387 -0.7073 -0.2819 -0.1579 -0.1815\n",
            "H-0\t-0.6281494498252869\tVeuillez me dire votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.6281494498252869\tVeuillez me dire votre nom et un peu de vous-même.\n",
            "P-0\t-2.7564 -0.3864 -0.8797 -0.4312 -0.1721 -0.3034 -0.6297 -0.1994 -0.7686 -0.9387 -0.7073 -0.2819 -0.1579 -0.1815\n",
            "H-0\t-0.7798036336898804\tMerci de me dire votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.7798036336898804\tMerci de me dire votre nom et un peu de vous-même.\n",
            "P-0\t-4.9458 -0.2245 -0.3576 -1.1888 -0.4086 -0.1679 -0.2633 -0.5277 -0.2001 -0.9251 -0.9691 -0.8695 -0.3117 -0.1560 -0.1813\n",
            "2021-04-08 16:50:50 | INFO | fairseq_cli.interactive | Total time: 14.080 seconds; translation time: 2.548\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_XJCM-g4QIM",
        "outputId": "d94b1da6-4098-43f3-eec5-43478ad643cc"
      },
      "source": [
        "%%bash\n",
        "MODEL_DIR=wmt14.en-fr.fconv-py\n",
        "echo \"Please tell me your name and a little about yourself .\" | fairseq-interactive \\\n",
        "    --path $MODEL_DIR/model.pt $MODEL_DIR \\\n",
        "    --tokenizer moses --bpe subword_nmt --bpe-codes $MODEL_DIR/bpecodes \\\n",
        "    --sampling --sampling-topp 0.9 --nbest 5 --source-lang en --target-lang fr --remove-bpe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-08 16:50:52 | INFO | fairseq_cli.interactive | Namespace(all_gather_list_size=16384, batch_size=1, batch_size_valid=None, beam=5, bf16=False, bpe='subword_nmt', bpe_codes='wmt14.en-fr.fconv-py/bpecodes', bpe_separator='@@', broadcast_buffers=False, bucket_cap_mb=25, buffer_size=1, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='wmt14.en-fr.fconv-py', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=0, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', input='-', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, moses_no_dash_splits=False, moses_no_escape=False, moses_source_lang=None, moses_target_lang=None, nbest=5, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='wmt14.en-fr.fconv-py/model.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe='@@ ', replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=True, sampling_topk=-1, sampling_topp=0.9, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', target_lang='fr', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer='moses', tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2021-04-08 16:50:52 | INFO | fairseq.tasks.translation | [en] dictionary: 43771 types\n",
            "2021-04-08 16:50:52 | INFO | fairseq.tasks.translation | [fr] dictionary: 43807 types\n",
            "2021-04-08 16:50:52 | INFO | fairseq_cli.interactive | loading model(s) from wmt14.en-fr.fconv-py/model.pt\n",
            "2021-04-08 16:51:03 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n",
            "2021-04-08 16:51:03 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n",
            "S-0\tPlease tell me your name and a little about yourself .\n",
            "W-0\t2.600\tseconds\n",
            "H-0\t-1.5681943893432617\tParlez @-@ moi brièvement de votre nom et vous @-@ même .\n",
            "D-0\t-1.5681943893432617\tParlez-moi brièvement de votre nom et vous-même.\n",
            "P-0\t-4.4182 -0.1850 -0.1128 -0.1384 -8.5462 -0.1935 -0.9205 -0.4523 -0.4186 -5.3293 -0.6749 -0.1980 -0.1853 -0.1818\n",
            "H-0\t-1.5689349174499512\tMerci de me trouver votre nom et un peu de vous @-@ même .\n",
            "D-0\t-1.5689349174499512\tMerci de me trouver votre nom et un peu de vous-même.\n",
            "P-0\t-4.9458 -0.2245 -0.3576 -11.3675 -0.7290 -0.2468 -0.3511 -1.2775 -0.3742 -0.5430 -1.6439 -0.8327 -0.2829 -0.1766 -0.1810\n",
            "H-0\t-1.937212586402893\tPour tout renseignement sur vous , dites @-@ moi votre nom .\n",
            "D-0\t-1.937212586402893\tPour tout renseignement sur vous, dites-moi votre nom.\n",
            "P-0\t-7.3289 -6.2315 -1.8031 -1.5807 -2.4611 -1.0810 -2.4481 -0.1704 -0.2198 -0.9769 -0.2064 -0.4911 -0.1848\n",
            "H-0\t-3.177128314971924\tContentez @-@ vous de se méfier de vous .\n",
            "D-0\t-3.177128314971924\tContentez-vous de se méfier de vous.\n",
            "P-0\t-14.8833 -0.1597 -0.1674 -0.1900 -0.7624 -0.5936 -9.5638 -11.0476 -0.6289 -0.8480 -1.5394 -0.7348 -0.1838\n",
            "H-0\t-3.216749429702759\tMerci de me faire part une petite citation de vous .\n",
            "D-0\t-3.216749429702759\tMerci de me faire part une petite citation de vous.\n",
            "P-0\t-4.9458 -0.2245 -0.3576 -5.1416 -0.6023 -12.0627 -1.3743 -8.9528 -1.0531 -2.1262 -1.5769 -0.1831\n",
            "2021-04-08 16:51:06 | INFO | fairseq_cli.interactive | Total time: 14.024 seconds; translation time: 2.600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97H-8SMqYgQN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}